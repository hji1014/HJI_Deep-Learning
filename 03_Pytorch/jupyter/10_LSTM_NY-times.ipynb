{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1k8Nk9IWm8ngNEc2VMTDDpdXyJ4X1oTtb","timestamp":1700700565085}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Dc1yPE3hluG","executionInfo":{"status":"ok","timestamp":1653718066899,"user_tz":-540,"elapsed":11153,"user":{"displayName":"텐초","userId":"16178379367655738070"}},"outputId":"355a0f48-9eb1-4909-991a-2fe3906742cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# 데이터 살펴보기"],"metadata":{"id":"6iWIw3d9hofA"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yUYHv3QyXBq5","executionInfo":{"status":"ok","timestamp":1653718070101,"user_tz":-540,"elapsed":1308,"user":{"displayName":"텐초","userId":"16178379367655738070"}},"outputId":"c99cda15-38d4-494b-c487-e7b7fa97232a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['abstract', 'articleID', 'articleWordCount', 'byline', 'documentType',\n","       'headline', 'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n","       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n","      dtype='object')\n"]}],"source":["import pandas as pd\n","import os\n","import string\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data/CH10/ArticlesApril2017.csv\")\n","print(df.columns)"]},{"cell_type":"markdown","source":["# 학습용 데이터셋 정의"],"metadata":{"id":"E6Vd-BH4h2AK"}},{"cell_type":"code","source":["import numpy as np\n","import glob\n","\n","from torch.utils.data.dataset import Dataset\n","\n","\n","class TextGeneration(Dataset):\n","    def clean_text(self, txt):\n","        # 모든 단어를 소문자로 바꾸고 특수문자를 제거\n","        txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n","        return txt\n","    def __init__(self):\n","        all_headlines = []\n","\n","        # ❶ 모든 헤드라인의 텍스트를 불러옴\n","        for filename in glob.glob(\"/content/drive/MyDrive/Colab Notebooks/data/CH10/*.csv\"):\n","            if 'Articles' in filename:\n","                article_df = pd.read_csv(filename)\n","\n","                # 데이터셋의 headline의 값을 all_headlines에 추가\n","                all_headlines.extend(list(article_df.headline.values))\n","                break\n","\n","        # ❷ headline 중 unknown 값은 제거\n","        all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n","\n","        # ❸ 구두점 제거 및 전처리가 된 문장들을 리스트로 반환\n","        self.corpus = [self.clean_text(x) for x in all_headlines]\n","        self.BOW = {}\n","\n","        # ➍ 모든 문장의 단어를 추출해 고유번호 지정\n","        for line in self.corpus:\n","            for word in line.split():\n","                if word not in self.BOW.keys():\n","                    self.BOW[word] = len(self.BOW.keys())\n","\n","        # 모델의 입력으로 사용할 데이터\n","        self.data = self.generate_sequence(self.corpus)\n","    def generate_sequence(self, txt):\n","        seq = []\n","\n","        for line in txt:\n","            line = line.split()\n","            line_bow = [self.BOW[word] for word in line]\n","\n","            # 단어 2개를 입력으로, 그다음 단어를 정답으로\n","            data = [([line_bow[i], line_bow[i+1]], line_bow[i+2])\n","            for i in range(len(line_bow)-2)]\n","\n","            seq.extend(data)\n","\n","        return seq\n","    def __len__(self):\n","        return len(self.data)\n","    def __getitem__(self, i):\n","        data = np.array(self.data[i][0])  # ❶ 입력 데이터\n","        label = np.array(self.data[i][1]).astype(np.float32)  # ❷ 출력 데이터\n","\n","        return data, label"],"metadata":{"id":"1QtO1ZfsXmJh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LSTM모델 정의"],"metadata":{"id":"Mx0YMUARiK9E"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","\n","class LSTM(nn.Module):\n","   def __init__(self, num_embeddings):\n","       super(LSTM, self).__init__()\n","\n","       # ❶ 밀집표현을 위한 임베딩층\n","       self.embed = nn.Embedding(\n","           num_embeddings=num_embeddings, embedding_dim=16)\n","\n","       # LSTM을 5개층을 쌓음\n","       self.lstm = nn.LSTM(\n","           input_size=16,\n","           hidden_size=64,\n","           num_layers=5,\n","           batch_first=True)\n","\n","       # 분류를 위한 MLP층\n","       self.fc1 = nn.Linear(128, num_embeddings)\n","       self.fc2 = nn.Linear(num_embeddings,num_embeddings)\n","\n","       # 활성화 함수\n","       self.relu = nn.ReLU()\n","\n","   def forward(self, x):\n","       x = self.embed(x)\n","\n","       # ❷ LSTM 모델의 예측값\n","       x, _ = self.lstm(x)\n","       x = torch.reshape(x, (x.shape[0], -1))\n","       x = self.fc1(x)\n","       x = self.relu(x)\n","       x = self.fc2(x)\n","\n","       return x"],"metadata":{"id":"iQ_NQkA7llFJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델 학습하기"],"metadata":{"id":"zHbQlFoZiRN7"}},{"cell_type":"code","source":["import tqdm\n","\n","from torch.utils.data.dataloader import DataLoader\n","from torch.optim.adam import Adam\n","\n","# 학습을 진행할 프로세서 정의\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","dataset = TextGeneration()  # 데이터셋 정의\n","model = LSTM(num_embeddings=len(dataset.BOW)).to(device)  # 모델 정의\n","loader = DataLoader(dataset, batch_size=64)\n","optim = Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(200):\n","   iterator = tqdm.tqdm(loader)\n","   for data, label in iterator:\n","       # 기울기 초기화\n","       optim.zero_grad()\n","\n","       # 모델의 예측값\n","       pred = model(torch.tensor(data, dtype=torch.long).to(device))\n","\n","       # 정답 레이블은 long 텐서로 반환해야 함\n","       loss = nn.CrossEntropyLoss()(\n","           pred, torch.tensor(label, dtype=torch.long).to(device))\n","\n","       # 오차 역전파\n","       loss.backward()\n","       optim.step()\n","\n","       iterator.set_description(f\"epoch{epoch} loss:{loss.item()}\")\n","\n","torch.save(model.state_dict(), \"lstm.pth\")"],"metadata":{"id":"E9x_OCUjnGe5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate(model, BOW, string=\"finding an \", strlen=10):\n","   device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","   print(f\"input word: {string}\")\n","\n","   with torch.no_grad():\n","       for p in range(strlen):\n","           # 입력 문장을 텐서로 변경\n","           words = torch.tensor(\n","               [BOW[w] for w in string.split()], dtype=torch.long).to(device)\n","\n","           # ❶\n","           input_tensor = torch.unsqueeze(words[-2:], dim=0)\n","           output = model(input_tensor)  # 모델을 이용해 예측\n","           output_word = (torch.argmax(output).cpu().numpy())\n","           string += list(BOW.keys())[output_word]  # 문장에 예측된 단어를 추가\n","           string += \" \"\n","\n","   print(f\"predicted sentence: {string}\")\n","\n","model.load_state_dict(torch.load(\"lstm.pth\", map_location=device))\n","pred = generate(model, dataset.BOW)"],"metadata":{"id":"n2aJFOvbn3Jm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652434439687,"user_tz":-540,"elapsed":255,"user":{"displayName":"텐초","userId":"16178379367655738070"}},"outputId":"f0bdce15-46fb-4a24-b2ba-06803cb1c1d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input word: finding an \n","predicted sentence: finding an expansive view and dims it today today sister sharp in \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"28rPwg8SxImr"},"execution_count":null,"outputs":[]}]}